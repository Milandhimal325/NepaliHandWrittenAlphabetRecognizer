{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rojan116/NepaliHandWrittenAlphabetRecognizer/blob/master/Untitled.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3iYjZ322UVRF",
        "colab_type": "code",
        "outputId": "dc448789-c7b3-4fb2-bd24-84d7bb83d7c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!git clone https://github.com/Rojan116/NepaliHandWrittenAlphabetRecognizer.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'NepaliHandWrittenAlphabetRecognizer' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MuijRLyyO7hR",
        "colab_type": "code",
        "outputId": "22f9e838-c32c-4bba-97c1-5ab21d527055",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd NepaliHandWrittenAlphabetRecognizer"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/NepaliHandWrittenAlphabetRecognizer\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Crogc0-lUqLO",
        "colab_type": "code",
        "outputId": "1b48d2fe-f329-4e67-ac75-7ea228c13a50",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import os,cv2\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "PATH = os.getcwd()\n",
        "print(PATH)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/NepaliHandWrittenAlphabetRecognizer\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9n5MQ8azVAYG",
        "colab_type": "code",
        "outputId": "29a4e6f7-32f6-49e2-e6bf-bb71b8eb73e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dev.py  \u001b[0m\u001b[01;34mdhrcdata\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dKHhT6JzXZ0G",
        "colab_type": "code",
        "outputId": "f60b1133-4a95-4f7e-c03b-d2f961dd1704",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Import libraries\n",
        "import os,cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from keras import backend as K\n",
        "K.set_image_dim_ordering('th')\n",
        "\n",
        "from keras.utils import np_utils\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
        "from keras.optimizers import SGD,RMSprop,adam\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9FuojsiLUeVF",
        "colab_type": "code",
        "outputId": "646cc360-ce6d-4e7a-ea65-2a2bffd12217",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1635
        }
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "PATH = os.getcwd()\n",
        "# Define data path\n",
        "data_path = PATH + '/dhrcdata/Train'\n",
        "data_dir_list = os.listdir(data_path)\n",
        "\n",
        "print(data_dir_list)\t\n",
        "\n",
        "# Define the number of classes\n",
        "num_classes = 46\n",
        "img_rows=128\n",
        "img_cols=128\n",
        "num_channel=1\n",
        "num_epoch=20\n",
        "\n",
        "img_data_list=[]\n",
        "\n",
        "\n",
        "for dataset in data_dir_list:\n",
        "\timg_list=os.listdir(data_path+'/'+ dataset)\n",
        "\tprint ('Loaded the images of dataset-'+'{}\\n'.format(dataset))\n",
        "\tfor img in img_list:\n",
        "\t\tinput_img=cv2.imread(data_path + '/'+ dataset + '/'+ img )\n",
        "\t\tinput_img=cv2.cvtColor(input_img, cv2.COLOR_BGR2GRAY)\n",
        "\t\tinput_img_resize=cv2.resize(input_img,(128,128))\n",
        "\t\timg_data_list.append(input_img_resize)\n",
        "\n",
        "img_data = np.array(img_data_list)\n",
        "img_data = img_data.astype('float32')\n",
        "img_data /= 255\n",
        "print (img_data.shape)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['digit_6', 'character_18_da', 'digit_8', 'character_13_daa', 'character_21_pa', 'digit_1', 'digit_0', 'character_36_gya', 'character_4_gha', 'character_30_motosaw', 'character_11_taamatar', 'character_34_chhya', 'digit_3', 'character_19_dha', 'character_14_dhaa', 'character_3_ga', 'character_29_waw', 'digit_7', 'character_22_pha', 'character_12_thaa', 'character_2_kha', 'character_8_ja', 'character_17_tha', 'character_15_adna', 'character_33_ha', 'character_1_ka', 'digit_5', 'character_31_petchiryakha', 'digit_2', 'character_20_na', 'character_23_ba', 'character_27_ra', 'digit_9', 'character_24_bha', 'character_25_ma', 'character_6_cha', 'character_7_chha', 'character_35_tra', 'character_16_tabala', 'character_5_kna', 'character_10_yna', 'character_32_patalosaw', 'character_26_yaw', 'character_9_jha', 'digit_4', 'character_28_la']\n",
            "Loaded the images of dataset-digit_6\n",
            "\n",
            "Loaded the images of dataset-character_18_da\n",
            "\n",
            "Loaded the images of dataset-digit_8\n",
            "\n",
            "Loaded the images of dataset-character_13_daa\n",
            "\n",
            "Loaded the images of dataset-character_21_pa\n",
            "\n",
            "Loaded the images of dataset-digit_1\n",
            "\n",
            "Loaded the images of dataset-digit_0\n",
            "\n",
            "Loaded the images of dataset-character_36_gya\n",
            "\n",
            "Loaded the images of dataset-character_4_gha\n",
            "\n",
            "Loaded the images of dataset-character_30_motosaw\n",
            "\n",
            "Loaded the images of dataset-character_11_taamatar\n",
            "\n",
            "Loaded the images of dataset-character_34_chhya\n",
            "\n",
            "Loaded the images of dataset-digit_3\n",
            "\n",
            "Loaded the images of dataset-character_19_dha\n",
            "\n",
            "Loaded the images of dataset-character_14_dhaa\n",
            "\n",
            "Loaded the images of dataset-character_3_ga\n",
            "\n",
            "Loaded the images of dataset-character_29_waw\n",
            "\n",
            "Loaded the images of dataset-digit_7\n",
            "\n",
            "Loaded the images of dataset-character_22_pha\n",
            "\n",
            "Loaded the images of dataset-character_12_thaa\n",
            "\n",
            "Loaded the images of dataset-character_2_kha\n",
            "\n",
            "Loaded the images of dataset-character_8_ja\n",
            "\n",
            "Loaded the images of dataset-character_17_tha\n",
            "\n",
            "Loaded the images of dataset-character_15_adna\n",
            "\n",
            "Loaded the images of dataset-character_33_ha\n",
            "\n",
            "Loaded the images of dataset-character_1_ka\n",
            "\n",
            "Loaded the images of dataset-digit_5\n",
            "\n",
            "Loaded the images of dataset-character_31_petchiryakha\n",
            "\n",
            "Loaded the images of dataset-digit_2\n",
            "\n",
            "Loaded the images of dataset-character_20_na\n",
            "\n",
            "Loaded the images of dataset-character_23_ba\n",
            "\n",
            "Loaded the images of dataset-character_27_ra\n",
            "\n",
            "Loaded the images of dataset-digit_9\n",
            "\n",
            "Loaded the images of dataset-character_24_bha\n",
            "\n",
            "Loaded the images of dataset-character_25_ma\n",
            "\n",
            "Loaded the images of dataset-character_6_cha\n",
            "\n",
            "Loaded the images of dataset-character_7_chha\n",
            "\n",
            "Loaded the images of dataset-character_35_tra\n",
            "\n",
            "Loaded the images of dataset-character_16_tabala\n",
            "\n",
            "Loaded the images of dataset-character_5_kna\n",
            "\n",
            "Loaded the images of dataset-character_10_yna\n",
            "\n",
            "Loaded the images of dataset-character_32_patalosaw\n",
            "\n",
            "Loaded the images of dataset-character_26_yaw\n",
            "\n",
            "Loaded the images of dataset-character_9_jha\n",
            "\n",
            "Loaded the images of dataset-digit_4\n",
            "\n",
            "Loaded the images of dataset-character_28_la\n",
            "\n",
            "(78200, 128, 128)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ukFJdp7jVIPX",
        "colab_type": "code",
        "outputId": "3339c7d0-fe49-4de3-a70a-7845ad1311a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Checking  grey or color image\n",
        "\n",
        "if num_channel==1:\n",
        "\tif K.image_dim_ordering()=='th':\n",
        "\t\timg_data= np.expand_dims(img_data, axis=1) \n",
        "\t\tprint (img_data.shape)\n",
        "\telse:\n",
        "\t\timg_data= np.expand_dims(img_data, axis=4) \n",
        "\t\tprint (img_data.shape)\n",
        "\t\t\n",
        "else:\n",
        "\tif K.image_dim_ordering()=='th':\n",
        "\t\timg_data=np.rollaxis(img_data,3,1)\n",
        "\t\tprint (img_data.shape)\n",
        "\t\t\n",
        "#%%\n",
        "USE_SKLEARN_PREPROCESSING=False\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(78200, 1, 128, 128)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2YE0YNJEek8s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if USE_SKLEARN_PREPROCESSING:\n",
        "\t# using sklearn for preprocessing\n",
        "\tfrom sklearn import preprocessing\n",
        "\t\n",
        "\tdef image_to_feature_vector(image, size=(128, 128)):\n",
        "\t\t# resize the image to a fixed size, then flatten the image into\n",
        "\t\t# a list of raw pixel intensities\n",
        "\t\treturn cv2.resize(image, size).flatten()\n",
        "\t\n",
        "\timg_data_list=[]\n",
        "\tfor dataset in data_dir_list:\n",
        "\t\timg_list=os.listdir(data_path+'/'+ dataset)\n",
        "\t\tprint ('Loaded the images of dataset-'+'{}\\n'.format(dataset))\n",
        "\t\tfor img in img_list:\n",
        "\t\t\tinput_img=cv2.imread(data_path + '/'+ dataset + '/'+ img )\n",
        "\t\t\tinput_img=cv2.cvtColor(input_img, cv2.COLOR_BGR2GRAY)\n",
        "\t\t\tinput_img_flatten=image_to_feature_vector(input_img,(128,128))\n",
        "\t\t\timg_data_list.append(input_img_flatten)\n",
        "\t\n",
        "\timg_data = np.array(img_data_list)\n",
        "\timg_data = img_data.astype('float32')\n",
        "\tprint (img_data.shape)\n",
        "\timg_data_scaled = preprocessing.scale(img_data)\n",
        "\tprint (img_data_scaled.shape)\n",
        "\t\n",
        "\tprint (np.mean(img_data_scaled))\n",
        "\tprint (np.std(img_data_scaled))\n",
        "\t\n",
        "\tprint (img_data_scaled.mean(axis=0))\n",
        "\tprint (img_data_scaled.std(axis=0))\n",
        "\t\n",
        "\tif K.image_dim_ordering()=='th':\n",
        "\t\timg_data_scaled=img_data_scaled.reshape(img_data.shape[0],num_channel,img_rows,img_cols)\n",
        "\t\tprint (img_data_scaled.shape)\n",
        "\t\t\n",
        "\telse:\n",
        "\t\timg_data_scaled=img_data_scaled.reshape(img_data.shape[0],img_rows,img_cols,num_channel)\n",
        "\t\tprint (img_data_scaled.shape)\n",
        "\t\n",
        "\t\n",
        "\tif K.image_dim_ordering()=='th':\n",
        "\t\timg_data_scaled=img_data_scaled.reshape(img_data.shape[0],num_channel,img_rows,img_cols)\n",
        "\t\tprint (img_data_scaled.shape)\n",
        "\t\t\n",
        "\telse:\n",
        "\t\timg_data_scaled=img_data_scaled.reshape(img_data.shape[0],img_rows,img_cols,num_channel)\n",
        "\t\tprint (img_data_scaled.shape)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T9uW3M0Cfdeo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if USE_SKLEARN_PREPROCESSING:\n",
        "\timg_data=img_data_scaled\n",
        "#%%\n",
        "# Assigning Labels\n",
        "\n",
        "# Define the number of classes\n",
        "num_classes = 46\n",
        "\n",
        "num_of_samples = img_data.shape[0]\n",
        "labels = np.ones((num_of_samples,),dtype='int64')\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FpkvdRR9fvf2",
        "colab_type": "code",
        "outputId": "77cf59ef-da8f-4708-e055-6abdd9299dc9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "labels"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, ..., 1, 1, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xYMBqGxfyJN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels[0:1700]=0\n",
        "labels[1700:3400]=1\n",
        "labels[3400:5100]=2\n",
        "labels[5100:6800]=3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qKP5bPf9gd2y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "names = ['ka','kha','gaa','gha']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PGDwBNJQgneS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y = np_utils.to_categorical(labels, num_classes)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YPm4Dyzegs9y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x,y = shuffle(img_data,Y, random_state=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "snX_XJMvgwbt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Split the dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=2)\n",
        "\n",
        "#%%\n",
        "# Defining the model\n",
        "input_shape=img_data[0].shape\n",
        "\t\t\t\t\t\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Convolution2D(32, 3,3,border_mode='same',input_shape=input_shape))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Convolution2D(32, 3, 3))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Convolution2D(64, 3, 3))\n",
        "model.add(Activation('relu'))\n",
        "#model.add(Convolution2D(64, 3, 3))\n",
        "#model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "#sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
        "#model.compile(loss='categorical_crossentropy', optimizer=sgd,metrics=[\"accuracy\"])\n",
        "model.compile(loss='categorical_crossentropy', optimizer='rmsprop',metrics=[\"accuracy\"])\n",
        "\n",
        "# Viewing model_configuration\n",
        "\n",
        "model.summary()\n",
        "model.get_config()\n",
        "model.layers[0].get_config()\n",
        "model.layers[0].input_shape\t\t\t\n",
        "model.layers[0].output_shape\t\t\t\n",
        "model.layers[0].get_weights()\n",
        "np.shape(model.layers[0].get_weights()[0])\n",
        "model.layers[0].trainable\n",
        "\n",
        "#%%\n",
        "# Training\n",
        "hist = model.fit(X_train, y_train, batch_size=16, nb_epoch=num_epoch, verbose=1, validation_data=(X_test, y_test))\n",
        "\n",
        "#hist = model.fit(X_train, y_train, batch_size=32, nb_epoch=20,verbose=1, validation_split=0.2)\n",
        "\n",
        "# Training with callbacks\n",
        "from keras import callbacks\n",
        "\n",
        "filename='model_train_new.csv'\n",
        "csv_log=callbacks.CSVLogger(filename, separator=',', append=False)\n",
        "\n",
        "early_stopping=callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=0, verbose=0, mode='min')\n",
        "\n",
        "filepath=\"Best-weights-my_model-{epoch:03d}-{loss:.4f}-{acc:.4f}.hdf5\"\n",
        "\n",
        "checkpoint = callbacks.ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
        "\n",
        "callbacks_list = [csv_log,early_stopping,checkpoint]\n",
        "\n",
        "hist = model.fit(X_train, y_train, batch_size=16, nb_epoch=num_epoch, verbose=1, validation_data=(X_test, y_test),callbacks=callbacks_list)\n",
        "\n",
        "\n",
        "# visualizing losses and accuracy\n",
        "train_loss=hist.history['loss']\n",
        "val_loss=hist.history['val_loss']\n",
        "train_acc=hist.history['acc']\n",
        "val_acc=hist.history['val_acc']\n",
        "xc=range(num_epoch)\n",
        "\n",
        "plt.figure(1,figsize=(7,5))\n",
        "plt.plot(xc,train_loss)\n",
        "plt.plot(xc,val_loss)\n",
        "plt.xlabel('num of Epochs')\n",
        "plt.ylabel('loss')\n",
        "plt.title('train_loss vs val_loss')\n",
        "plt.grid(True)\n",
        "plt.legend(['train','val'])\n",
        "#print plt.style.available # use bmh, classic,ggplot for big pictures\n",
        "plt.style.use(['classic'])\n",
        "\n",
        "plt.figure(2,figsize=(7,5))\n",
        "plt.plot(xc,train_acc)\n",
        "plt.plot(xc,val_acc)\n",
        "plt.xlabel('num of Epochs')\n",
        "plt.ylabel('accuracy')\n",
        "plt.title('train_acc vs val_acc')\n",
        "plt.grid(True)\n",
        "plt.legend(['train','val'],loc=4)\n",
        "#print plt.style.available # use bmh, classic,ggplot for big pictures\n",
        "plt.style.use(['classic'])\n",
        "\n",
        "#%%\n",
        "\n",
        "# Evaluating the model\n",
        "\n",
        "score = model.evaluate(X_test, y_test, show_accuracy=True, verbose=0)\n",
        "print('Test Loss:', score[0])\n",
        "print('Test accuracy:', score[1])\n",
        "\n",
        "test_image = X_test[0:1]\n",
        "print (test_image.shape)\n",
        "\n",
        "print(model.predict(test_image))\n",
        "print(model.predict_classes(test_image))\n",
        "print(y_test[0:1])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pqjKA5FehFRI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}